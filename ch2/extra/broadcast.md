## 广播语义

广播（Broadcasting）是指：**当两个张量的形状不完全相同时，PyTorch 会自动“扩展”较小的张量，使其形状与较大的张量匹配，从而支持逐元素运算（element-wise operations）**。

在进行支持广播语义的逐元素操作时，如果两个张量的形状不完全匹配，PyTorch会自动使用广播机制来进行形状的扩展，使得两个张量的形状相同，从而进行逐元素操作。

当一对张量满足下面的**条件**时，它们才是可以被“广播”的。

1. 每个张量至少有一个维度。
2. 迭代维度尺寸时，从**尾部**（也就是从后往前）开始，依次每个维度的尺寸必须满足以下之一：
   - **相等**。
   - 其中一个张量的在该维度维度**列数为1**。
   - 其中一个张量**不存在**这个维度。



对于可广播的张量，广播机制会进行如下操作

1. 对于不存在的维度，将其维度补至1（此操作不涉及元素数目改变）
   - 这一步以后，两个张量一定是同维度的，但是每个维度的列数不一定相等
2. 对于列数不相等的维度，将该列通过**虚拟复制**的方式扩展到更多列上
   - 虚拟复制指的是在索引时将该维度的其他列都索引到`[0]`列上，不涉及数据复制从而节约内存空间

例子：

```python
a = torch.tensor([[1, 2, 3],     # shape: [2, 3]
                  [4, 5, 6]])

b = torch.tensor([[10],          # shape: [2, 1]
                  [20]])
c = a + b

```

上面的计算中，b就会被虚拟复制成

```
torch.tensor([[10, 10, 10],
			[20, 20, 20]
```



这也可以解释为什么要从后往前遍历维度，因为如此一来，需要虚拟复制的数据都是确定的